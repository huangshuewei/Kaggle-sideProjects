{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/hsw1212/cirfar10-classification-resnet50-81?scriptVersionId=139383501\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Load cifar10 data\n(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n\nx_train = x_train\nx_test = x_test\n\n# x_train = np.moveaxis(x_train, [0,1,2,3], [0,2,3,1])\n# x_test = np.moveaxis(x_test, [0,1,2,3], [0,2,3,1])\n\ny_train = tf.keras.utils.to_categorical(y_train,num_classes=10)\ny_test = tf.keras.utils.to_categorical(y_test,num_classes=10)\n\nprint(x_train.shape)\nprint(y_train.shape)\nlabels = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']\n# labels","metadata":{"execution":{"iopub.status.busy":"2023-08-09T08:26:11.168662Z","iopub.execute_input":"2023-08-09T08:26:11.169087Z","iopub.status.idle":"2023-08-09T08:26:11.821467Z","shell.execute_reply.started":"2023-08-09T08:26:11.169052Z","shell.execute_reply":"2023-08-09T08:26:11.820371Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"(50000, 32, 32, 3)\n(50000, 10)\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\nimport torch.optim as optim\nfrom torchvision.models import resnet50\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n# Build ResNet50 model\nmodel = resnet50(pretrained = True)\n# ResNet50 = ResNet50.float()\n\n# Dont train weights in feature extractor layers\n# for param in ResNet50.parameters():\n#     param.requires_grad = False \n'''\ndef init_weights(m):\n    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n        if m.bias is not None:\n            nn.init.constant_(m.bias, 0)\n'''\n# Connect to fully connnected layer\nmodel.fc = nn.Sequential(\n    nn.Linear(2048,512),\n    nn.ReLU(inplace=True),\n    nn.Linear(512,64),\n    nn.ReLU(inplace=True),\n    nn.Linear(64,10)\n)\n# model.apply(init_weights)\nmodel.to(device)\n\nmodel","metadata":{"execution":{"iopub.status.busy":"2023-08-09T08:26:11.824406Z","iopub.execute_input":"2023-08-09T08:26:11.825412Z","iopub.status.idle":"2023-08-09T08:26:12.356137Z","shell.execute_reply.started":"2023-08-09T08:26:11.825375Z","shell.execute_reply":"2023-08-09T08:26:12.354928Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (4): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (5): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Sequential(\n    (0): Linear(in_features=2048, out_features=512, bias=True)\n    (1): ReLU(inplace=True)\n    (2): Linear(in_features=512, out_features=64, bias=True)\n    (3): ReLU(inplace=True)\n    (4): Linear(in_features=64, out_features=10, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Set data loader\nclass cifar10Dataset(Dataset):\n    def __init__(self, imgs, labels, transform=None):\n        self.imgs = imgs\n        self.labels = labels\n        self.transforms = transform\n\n    def __len__(self):\n        return len(self.imgs)\n    \n    def __getitem__(self, index):\n        x = self.imgs[index]\n        y = self.labels[index]\n\n        if self.transforms:\n            x = self.transforms(x)\n\n        x = x.float()\n        return x, y\n\n# Split train and validation\nx_train, x_val, y_train, y_val = train_test_split(x_train, \n                                                  y_train, \n                                                  test_size=0.2, \n                                                  random_state=100,\n                                                  shuffle=True)\n\nlearningRate = 0.001\nbatch_size = 64\n\n# Set loss function and optimiser\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(),lr = learningRate)\n\nstats = ((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\ntransform = transforms.Compose([transforms.ToTensor(),\n                                # transforms.RandomCrop(32, padding=4, padding_mode='reflect'),\n                                # transforms.RandomHorizontalFlip(),\n                                transforms.Normalize(*stats,inplace=True)])\n\ntrain_dataset = cifar10Dataset(x_train, y_train, transform)\nval_dataset = cifar10Dataset(x_val, y_val, transform)\ntest_dataset = cifar10Dataset(x_test, y_test, transform)\ntrain_loader = DataLoader(dataset=train_dataset, batch_size= batch_size, shuffle=True)\nval_loader = DataLoader(dataset=val_dataset, batch_size= batch_size, shuffle=True)\ntest_loader = DataLoader(dataset=test_dataset, batch_size= batch_size, shuffle=True)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-09T08:26:12.357639Z","iopub.execute_input":"2023-08-09T08:26:12.358283Z","iopub.status.idle":"2023-08-09T08:26:12.429378Z","shell.execute_reply.started":"2023-08-09T08:26:12.358239Z","shell.execute_reply":"2023-08-09T08:26:12.428236Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# Train loop\nnum_epoch = 25\nbest_val_accuracy = 0.0\n\nfor epoch in range(num_epoch):\n    model.train()\n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        correct = 0\n        total = 0\n        for images, labels in val_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            _, labels = torch.max(labels, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n        val_accuracy = correct / total\n        if val_accuracy > best_val_accuracy:\n            best_val_accuracy = val_accuracy\n            torch.save(model.state_dict(), 'best_model.pth')\n        \n        print(f'Epoch [{epoch+1}/{num_epoch}], Validation Accuracy: {val_accuracy:.4f}, BEST Accuracy: {best_val_accuracy:.4f}')\n\nprint('Training Finished!')\n","metadata":{"execution":{"iopub.status.busy":"2023-08-09T08:26:12.431901Z","iopub.execute_input":"2023-08-09T08:26:12.432305Z","iopub.status.idle":"2023-08-09T08:37:58.142518Z","shell.execute_reply.started":"2023-08-09T08:26:12.432268Z","shell.execute_reply":"2023-08-09T08:37:58.141316Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Epoch [1/25], Validation Accuracy: 0.7224, BEST Accuracy: 0.7224\nEpoch [2/25], Validation Accuracy: 0.7503, BEST Accuracy: 0.7503\nEpoch [3/25], Validation Accuracy: 0.7716, BEST Accuracy: 0.7716\nEpoch [4/25], Validation Accuracy: 0.7982, BEST Accuracy: 0.7982\nEpoch [5/25], Validation Accuracy: 0.7992, BEST Accuracy: 0.7992\nEpoch [6/25], Validation Accuracy: 0.7952, BEST Accuracy: 0.7992\nEpoch [7/25], Validation Accuracy: 0.8004, BEST Accuracy: 0.8004\nEpoch [8/25], Validation Accuracy: 0.7898, BEST Accuracy: 0.8004\nEpoch [9/25], Validation Accuracy: 0.8091, BEST Accuracy: 0.8091\nEpoch [10/25], Validation Accuracy: 0.8051, BEST Accuracy: 0.8091\nEpoch [11/25], Validation Accuracy: 0.8170, BEST Accuracy: 0.8170\nEpoch [12/25], Validation Accuracy: 0.8084, BEST Accuracy: 0.8170\nEpoch [13/25], Validation Accuracy: 0.7975, BEST Accuracy: 0.8170\nEpoch [14/25], Validation Accuracy: 0.8041, BEST Accuracy: 0.8170\nEpoch [15/25], Validation Accuracy: 0.7998, BEST Accuracy: 0.8170\nEpoch [16/25], Validation Accuracy: 0.8030, BEST Accuracy: 0.8170\nEpoch [17/25], Validation Accuracy: 0.8047, BEST Accuracy: 0.8170\nEpoch [18/25], Validation Accuracy: 0.8015, BEST Accuracy: 0.8170\nEpoch [19/25], Validation Accuracy: 0.8104, BEST Accuracy: 0.8170\nEpoch [20/25], Validation Accuracy: 0.7919, BEST Accuracy: 0.8170\nEpoch [21/25], Validation Accuracy: 0.8041, BEST Accuracy: 0.8170\nEpoch [22/25], Validation Accuracy: 0.8163, BEST Accuracy: 0.8170\nEpoch [23/25], Validation Accuracy: 0.8091, BEST Accuracy: 0.8170\nEpoch [24/25], Validation Accuracy: 0.8117, BEST Accuracy: 0.8170\nEpoch [25/25], Validation Accuracy: 0.8118, BEST Accuracy: 0.8170\nTraining Finished!\n","output_type":"stream"}]},{"cell_type":"code","source":"model.load_state_dict(torch.load('best_model.pth'))\nmodel.eval()\n\ntotal = 0\ncorrect = 0\n\nfor images, labels in test_loader:\n    images, labels = images.to(device), labels.to(device)\n    batch_outputs = model(images) \n    _, predicted = torch.max(batch_outputs, 1)\n    _, labels = torch.max(labels, 1)\n    total += labels.size(0)\n    correct += (predicted == labels).sum().item()\n    \ntest_accuracy = correct / total\nprint('Test accuracy: ', test_accuracy)","metadata":{"execution":{"iopub.status.busy":"2023-08-09T08:37:58.144437Z","iopub.execute_input":"2023-08-09T08:37:58.144867Z","iopub.status.idle":"2023-08-09T08:38:00.873387Z","shell.execute_reply.started":"2023-08-09T08:37:58.144829Z","shell.execute_reply":"2023-08-09T08:38:00.872256Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Test accuracy:  0.812\n","output_type":"stream"}]}]}